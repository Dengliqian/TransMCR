# TransMCR

### Abstract

Facial expression recognition (FER) plays a vital role in areas such as humanâ€“robot interaction, security monitoring, and robot vision. However, FER encounters several challenges, including occlusions, lighting conditions and arbitrary face orientations. To tackle these challenges, we identify two cues from face images, namely muscle contraction relationships and texture deformation relationships. On the basis of the cues, three key anatomical insights from facial images are revealed: (i) facial muscle contraction field, (ii) regional coding of muscle interactions, and (iii) skin texture deformation relationship. To leverage three key insights above, a novel relationship-driven FER method is proposed based on Transformer architecture, in which muscle contraction and texture deformation relationships can be learned. Specifically, we introduce Contraction Relationship Mining (CRM) to explore muscle contraction relationships through visual and contraction tokens. Then the Contraction Orientation Refinement (COR) scheme is developed to refine the
relationship between facial muscles. Finally, the Texture Deformation Representation (TDR) module captures fine-grained superficial skin textures. Experiments on the RAF-DB, KDEF and FERPlus datasets show significant improvements of our proposed TransMCR framework over state-of-the-art FER methods.

---
### The code of TransMCR will be avaliable soon
